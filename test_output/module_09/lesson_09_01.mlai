<?xml version="1.0" encoding="UTF-8"?>
<Lesson>
  <Meta>
    <Id>lesson-09-01</Id>
    <Title>Spike-Timing-Dependent Plasticity (STDP)</Title>
    <Version>1</Version>
    <Tags>
      <Tag>STDP</Tag>
      <Tag>synaptic plasticity</Tag>
      <Tag>temporal asymmetry</Tag>
      <Tag>sequence learning</Tag>
      <Tag>Hebbian learning</Tag>
      <Tag>neural networks</Tag>
      <Tag>computational neuroscience</Tag>
    </Tags>
  </Meta>

  <H1>Spike-Timing-Dependent Plasticity (STDP)</H1>

  <Body>STDP implements a local, temporally asymmetric learning rule where synaptic strength changes depend on precise spike timing, providing a biologically plausible mechanism for learning temporal sequences and causal relationships. This lesson builds upon synaptic transmission concepts from Module 3, where we treated synaptic weights as fixed parameters. STDP introduces plasticity—the ability of synapses to strengthen or weaken based on the relative timing of pre- and postsynaptic spikes.</Body>

  <H2>Experimental Foundations of STDP</H2>

  <Body>The discovery of STDP emerged from seminal experiments by Bi and Poo (1998) and Markram et al. (1997), who demonstrated that the sign and magnitude of synaptic modification depend critically on the millisecond-precise timing between presynaptic and postsynaptic action potentials. When the presynaptic spike precedes the postsynaptic spike (pre→post), the synapse undergoes long-term potentiation (LTP). Conversely, when the postsynaptic spike precedes the presynaptic spike (post→pre), the synapse undergoes long-term depression (LTD).</Body>

  <Body>This temporal asymmetry has profound computational implications: STDP effectively implements a causality detector. If neuron A consistently fires before neuron B, the synapse from A to B strengthens—precisely the scenario where A's activity might cause B's firing. This makes STDP a biologically plausible implementation of Hebb's postulate that "cells that fire together wire together," but with crucial temporal refinement.</Body>

  <FlashCard id="fc1">
    <Front>What is the key difference between STDP and classical Hebbian learning?</Front>
    <Back>STDP incorporates temporal order information: synaptic changes depend on the precise timing difference (Δt) between pre- and postsynaptic spikes, not just their co-occurrence. Pre→post timing causes LTP, while post→pre timing causes LTD.</Back>
  </FlashCard>

  <FlashCard id="fc2">
    <Front>What does the temporal asymmetry in STDP represent computationally?</Front>
    <Back>Temporal asymmetry implements causality detection: synapses strengthen when presynaptic activity precedes postsynaptic activity (potential causal relationship) and weaken when the order is reversed (anti-causal).</Back>
  </FlashCard>

  <H2>The STDP Learning Window</H2>

  <Body>The STDP learning rule is typically described by a temporally asymmetric function that specifies the change in synaptic weight Δw as a function of the spike timing difference Δt = t_post - t_pre:</Body>

  <Code lang="python">
# STDP window function
def stdp_window(delta_t, A_plus=0.01, A_minus=0.012, tau_plus=20.0, tau_minus=20.0):
    """
    Compute synaptic weight change based on spike timing difference.

    Parameters:
    -----------
    delta_t : float or array
        Time difference t_post - t_pre (ms)
    A_plus : float
        Maximum LTP amplitude
    A_minus : float
        Maximum LTD amplitude
    tau_plus : float
        LTP time constant (ms)
    tau_minus : float
        LTD time constant (ms)

    Returns:
    --------
    delta_w : float or array
        Synaptic weight change
    """
    import numpy as np

    delta_w = np.where(
        delta_t &gt; 0,
        A_plus * np.exp(-delta_t / tau_plus),    # LTP: pre before post
        -A_minus * np.exp(delta_t / tau_minus)   # LTD: post before pre
    )
    return delta_w
</Code>

  <Body>The mathematical form of the STDP window is:</Body>

  <Body>For Δt &gt; 0 (pre before post, LTP): Δw = A₊ exp(-Δt/τ₊)</Body>
  <Body>For Δt &lt; 0 (post before pre, LTD): Δw = -A₋ exp(Δt/τ₋)</Body>

  <Body>Typical parameter values derived from experiments: A₊ ≈ 0.01, A₋ ≈ 0.012 (LTD slightly stronger), τ₊ ≈ τ₋ ≈ 20 ms. The slight asymmetry in amplitudes (A₋ &gt; A₊) helps prevent runaway potentiation and contributes to weight stability.</Body>

  <FlashCard id="fc3">
    <Front>What are the typical time constants (τ) for STDP windows in cortical synapses?</Front>
    <Back>Approximately 20 ms for both potentiation (τ₊) and depression (τ₋). This narrow temporal window (~40 ms total) reflects the millisecond precision of STDP and matches the timescale of membrane potential dynamics.</Back>
  </FlashCard>

  <SingleSelect id="q1">
    <Prompt>In the standard STDP learning rule, if a presynaptic spike occurs 10 ms before the postsynaptic spike (Δt = +10 ms), what happens to the synaptic weight?</Prompt>
    <Options>
      <Option correct="true">The weight increases (LTP)</Option>
      <Option>The weight decreases (LTD)</Option>
      <Option>The weight remains unchanged</Option>
      <Option>The synapse is eliminated</Option>
    </Options>
  </SingleSelect>

  <SingleSelect id="q2">
    <Prompt>Why is LTD magnitude (A₋) typically slightly larger than LTP magnitude (A₊) in experimental STDP measurements?</Prompt>
    <Options>
      <Option correct="true">It helps prevent runaway potentiation and contributes to weight stability</Option>
      <Option>It is an experimental artifact with no functional significance</Option>
      <Option>LTD requires more molecular machinery than LTP</Option>
      <Option>It ensures all synapses eventually depress to zero</Option>
    </Options>
  </SingleSelect>

  <H2>Additive vs. Multiplicative STDP</H2>

  <Body>A critical distinction in STDP implementations concerns weight dependence. In additive STDP, the weight change is independent of current weight:</Body>

  <Body>w(t + dt) = w(t) + Δw</Body>

  <Body>In multiplicative (or weight-dependent) STDP, the change scales with distance from weight bounds:</Body>

  <Body>For LTP: Δw → Δw × (w_max - w) / w_max</Body>
  <Body>For LTD: Δw → Δw × w / w_max</Body>

  <Code lang="python">
import numpy as np

class STDPSynapse:
    """
    STDP synapse implementation supporting additive and multiplicative rules.
    """

    def __init__(self, w_init=0.5, w_min=0.0, w_max=1.0,
                 A_plus=0.01, A_minus=0.012,
                 tau_plus=20.0, tau_minus=20.0,
                 multiplicative=False):
        self.w = w_init
        self.w_min = w_min
        self.w_max = w_max
        self.A_plus = A_plus
        self.A_minus = A_minus
        self.tau_plus = tau_plus
        self.tau_minus = tau_minus
        self.multiplicative = multiplicative

        # Eligibility traces for online learning
        self.x_pre = 0.0   # Presynaptic trace
        self.x_post = 0.0  # Postsynaptic trace

    def update_traces(self, dt):
        """Decay eligibility traces."""
        self.x_pre *= np.exp(-dt / self.tau_plus)
        self.x_post *= np.exp(-dt / self.tau_minus)

    def pre_spike(self):
        """Process presynaptic spike."""
        # LTD: pre after post
        if self.multiplicative:
            delta_w = -self.A_minus * self.x_post * (self.w / self.w_max)
        else:
            delta_w = -self.A_minus * self.x_post

        self.w = np.clip(self.w + delta_w, self.w_min, self.w_max)
        self.x_pre += 1.0

    def post_spike(self):
        """Process postsynaptic spike."""
        # LTP: post after pre
        if self.multiplicative:
            delta_w = self.A_plus * self.x_pre * ((self.w_max - self.w) / self.w_max)
        else:
            delta_w = self.A_plus * self.x_pre

        self.w = np.clip(self.w + delta_w, self.w_min, self.w_max)
        self.x_post += 1.0
</Code>

  <Body>Additive STDP leads to bimodal weight distributions (weights cluster near bounds) and strong competition between synapses. Multiplicative STDP produces unimodal distributions and weaker competition but better stability. The choice affects learning dynamics, memory capacity, and biological realism.</Body>

  <FlashCard id="fc4">
    <Front>What weight distribution does additive STDP typically produce, and why?</Front>
    <Back>Additive STDP produces bimodal weight distributions where weights cluster near w_min or w_max. This occurs because weight changes are independent of current weight, so strong synapses keep strengthening and weak synapses keep weakening until they hit bounds.</Back>
  </FlashCard>

  <MultiSelect id="q3">
    <Prompt>Which of the following are advantages of multiplicative STDP over additive STDP? (Select all that apply)</Prompt>
    <Options>
      <Option correct="true">More stable weight distributions</Option>
      <Option correct="true">Self-normalizing behavior without explicit weight bounds</Option>
      <Option>Stronger synaptic competition</Option>
      <Option correct="true">Unimodal weight distributions that may better match experimental data</Option>
      <Option>Faster learning of temporal sequences</Option>
    </Options>
  </MultiSelect>

  <H2>Weight Dynamics and Stability Analysis</H2>

  <Body>The evolution of synaptic weights under STDP can be described by integrating over all spike pairs:</Body>

  <Body>dw/dt = Σ_spikes STDP_window(Δt)</Body>

  <Body>For a neuron receiving inputs from multiple presynaptic neurons with different firing rates and correlations, we can derive the expected weight change by averaging over spike statistics. For Poisson inputs with rate r_pre correlated with postsynaptic rate r_post:</Body>

  <Code lang="python">
import numpy as np
from scipy.integrate import quad

def expected_weight_change(r_pre, r_post, correlation,
                           A_plus=0.01, A_minus=0.012,
                           tau_plus=20.0, tau_minus=20.0):
    """
    Compute expected weight change rate under STDP for correlated Poisson neurons.

    Parameters:
    -----------
    r_pre : float
        Presynaptic firing rate (Hz)
    r_post : float
        Postsynaptic firing rate (Hz)
    correlation : float
        Cross-correlation at zero lag

    Returns:
    --------
    dw_dt : float
        Expected rate of weight change
    """
    # Convert rates to per-ms
    r_pre_ms = r_pre / 1000.0
    r_post_ms = r_post / 1000.0

    # Uncorrelated contribution (independent Poisson)
    # Integrate STDP window weighted by spike pair probability
    ltp_integral = A_plus * tau_plus  # ∫₀^∞ A_+ exp(-t/τ_+) dt
    ltd_integral = A_minus * tau_minus  # ∫₀^∞ A_- exp(-t/τ_-) dt

    dw_uncorr = r_pre_ms * r_post_ms * (ltp_integral - ltd_integral)

    # Correlated contribution (excess coincidences)
    # Assuming correlation decays exponentially
    dw_corr = correlation * r_pre_ms * (A_plus + A_minus) * 0.5

    return dw_uncorr + dw_corr
</Code>

  <Body>A critical stability concern is weight explosion: without constraints, STDP can lead to runaway potentiation where strong synapses drive postsynaptic firing, which further strengthens them. Several mechanisms provide stability:</Body>

  <Body>1. Hard weight bounds: w ∈ [w_min, w_max]</Body>
  <Body>2. Multiplicative STDP: weight-dependent scaling</Body>
  <Body>3. Heterosynaptic plasticity: global normalization across synapses</Body>
  <Body>4. Intrinsic plasticity: homeostatic regulation of neuronal excitability</Body>
  <Body>5. Metaplasticity: activity-dependent modification of plasticity rules</Body>

  <SortQuiz id="q4">
    <Prompt>Order these mechanisms from most local (acting on single synapses) to most global (acting across the neuron or network):</Prompt>
    <SortedItems>
      <Item>Hard weight bounds at individual synapses</Item>
      <Item>Multiplicative (weight-dependent) STDP</Item>
      <Item>Heterosynaptic plasticity (normalization across synapses)</Item>
      <Item>Intrinsic plasticity (homeostatic excitability)</Item>
      <Item>Network-level activity regulation</Item>
    </SortedItems>
  </SortQuiz>

  <H2>Sequence Learning with STDP</H2>

  <Body>One of STDP's most powerful computational functions is learning temporal sequences. When a network receives sequential inputs A→B→C, STDP strengthens synapses in the direction of the sequence (A→B, B→C) while weakening reverse connections (B→A, C→B). This creates attractor dynamics that can replay learned sequences.</Body>

  <Code lang="python">
import numpy as np
import matplotlib.pyplot as plt

class STDPNetwork:
    """
    Recurrent network with STDP for sequence learning.
    """

    def __init__(self, n_neurons, w_init=0.1, w_max=1.0):
        self.n = n_neurons
        self.W = np.ones((n_neurons, n_neurons)) * w_init
        np.fill_diagonal(self.W, 0)  # No self-connections
        self.w_max = w_max

        # STDP parameters
        self.A_plus = 0.02
        self.A_minus = 0.024
        self.tau_plus = 20.0
        self.tau_minus = 20.0

        # Spike traces
        self.traces = np.zeros(n_neurons)

    def present_sequence(self, sequence, inter_spike_interval=10.0):
        """
        Present a sequence of neuron activations to the network.

        Parameters:
        -----------
        sequence : list
            Indices of neurons to activate in order
        inter_spike_interval : float
            Time between sequential spikes (ms)
        """
        # Reset traces
        self.traces = np.zeros(self.n)

        for i, neuron_idx in enumerate(sequence):
            # Update traces with time elapsed
            if i &gt; 0:
                self.traces *= np.exp(-inter_spike_interval / self.tau_plus)

            # Apply STDP: this neuron as postsynaptic
            # LTP for synapses from recently active neurons
            delta_w_ltp = self.A_plus * self.traces
            self.W[:, neuron_idx] += delta_w_ltp

            # Apply STDP: this neuron as presynaptic for future
            # LTD for synapses to recently active neurons
            delta_w_ltd = -self.A_minus * self.traces
            self.W[neuron_idx, :] += delta_w_ltd

            # Update trace for this neuron
            self.traces[neuron_idx] = 1.0

            # Clip weights
            self.W = np.clip(self.W, 0, self.w_max)
            np.fill_diagonal(self.W, 0)

    def compute_sequence_strength(self, sequence):
        """Compute total synaptic strength along a sequence."""
        strength = 0.0
        for i in range(len(sequence) - 1):
            strength += self.W[sequence[i], sequence[i+1]]
        return strength

# Example: Train network on sequence
np.random.seed(42)
network = STDPNetwork(n_neurons=10)
sequence = [0, 3, 7, 2, 9]  # Training sequence

# Present sequence multiple times
for epoch in range(50):
    network.present_sequence(sequence)

# Check learned weights along sequence
print("Synaptic weights along learned sequence:")
for i in range(len(sequence) - 1):
    pre, post = sequence[i], sequence[i+1]
    print(f"  W[{pre}→{post}] = {network.W[pre, post]:.3f}")
</Code>

  <Body>After training, the network develops a feedforward chain structure that preferentially propagates activity along the learned sequence. This provides a substrate for temporal pattern completion and sequence recall—crucial for episodic memory and motor planning.</Body>

  <MatchPairs id="q5">
    <Prompt>Match each STDP-related phenomenon with its computational consequence:</Prompt>
    <Pairs>
      <Pair><Left>Pre→Post timing causes LTP</Left><Right>Causal relationships are strengthened</Right></Pair>
      <Pair><Left>Post→Pre timing causes LTD</Left><Right>Anti-causal connections weaken</Right></Pair>
      <Pair><Left>Narrow temporal window (~40 ms)</Left><Right>Millisecond-precise temporal coding</Right></Pair>
      <Pair><Left>Bimodal weight distribution</Left><Right>Winner-take-all competition</Right></Pair>
    </Pairs>
    <RightDistractors>
      <Distractor>Rate coding predominates</Distractor>
      <Distractor>All synapses become equal</Distractor>
    </RightDistractors>
  </MatchPairs>

  <H2>STDP and Temporal Difference Learning</H2>

  <Body>A profound connection exists between STDP and temporal difference (TD) learning from reinforcement learning theory. Both implement mechanisms sensitive to temporal prediction errors. In TD learning, value estimates are updated based on the difference between predicted and actual rewards. Similarly, STDP modifies synapses based on whether presynaptic activity successfully predicts postsynaptic firing.</Body>

  <Body>Consider a synapse where presynaptic input predicts postsynaptic spiking: if the prediction is accurate (pre fires → post fires), the synapse strengthens (LTP). If the prediction fails (pre fires but post doesn't fire within the temporal window), or if post fires unexpectedly (post fires first → pre fires), the synapse weakens (LTD).</Body>

  <Code lang="python">
# Conceptual mapping between STDP and TD learning

"""
STDP Framework:
- State: Presynaptic spike (eligibility trace)
- Prediction: Expected postsynaptic spike
- Outcome: Actual postsynaptic spike timing
- Update: Δw based on timing difference

TD Learning Framework:
- State: s_t
- Prediction: V(s_t) = E[R_{t+1} + γV(s_{t+1})]
- Outcome: Actual reward r_{t+1}
- Update: δ = r_{t+1} + γV(s_{t+1}) - V(s_t)

Correspondence:
- Presynaptic trace ~ Eligibility trace e(s,a)
- Post spike timing ~ Reward signal
- STDP window ~ TD error temporal kernel
- Weight change ~ Value update
"""

def td_stdp_analogy():
    """
    Demonstrate conceptual similarity between STDP and TD learning.
    """
    import numpy as np

    # Simplified STDP as predictive learning
    def stdp_prediction_error(predicted_timing, actual_timing, tau=20.0):
        """
        STDP as temporal prediction error.
        predicted_timing: when post spike was expected (based on pre spike)
        actual_timing: when post spike actually occurred
        """
        if actual_timing is None:
            # No post spike - prediction failed
            return -0.01  # LTD

        delta_t = actual_timing - predicted_timing

        if delta_t &gt; 0:
            # Post after pre: prediction somewhat accurate
            return 0.01 * np.exp(-delta_t / tau)
        else:
            # Post before pre: anti-prediction
            return -0.012 * np.exp(delta_t / tau)

    return stdp_prediction_error
</Code>

  <FlashCard id="fc5">
    <Front>How does STDP relate to temporal difference (TD) learning?</Front>
    <Back>Both implement prediction error-based learning. STDP can be viewed as learning to predict postsynaptic firing from presynaptic activity: LTP occurs when predictions are accurate (pre→post), LTD when predictions fail (post→pre or no post spike). The STDP window acts similarly to a TD error temporal kernel.</Back>
  </FlashCard>

  <FlashCard id="fc6">
    <Front>What is an eligibility trace in the context of STDP?</Front>
    <Back>An eligibility trace tracks recent presynaptic (or postsynaptic) spikes with exponential decay. It marks synapses as "eligible" for modification when a subsequent spike arrives, enabling online implementation of STDP without storing exact spike times.</Back>
  </FlashCard>

  <FillBlanks id="q6">
    <Prompt>
      In STDP, when Δt = t_post - t_pre is positive, the synapse undergoes <Blank>potentiation</Blank> because the presynaptic spike <Blank>preceded</Blank> the postsynaptic spike. The magnitude of weight change decays <Blank>exponentially</Blank> with |Δt|, with a time constant typically around <Blank>20</Blank> milliseconds.
    </Prompt>
    <Distractors>
      <Distractor>depression</Distractor>
      <Distractor>followed</Distractor>
      <Distractor>linearly</Distractor>
      <Distractor>200</Distractor>
      <Distractor>quadratically</Distractor>
    </Distractors>
  </FillBlanks>

  <H2>Simulation: STDP Network Learning</H2>

  <Body>Let's implement a complete simulation demonstrating STDP learning in a recurrent network, showing weight evolution and sequence replay:</Body>

  <Code lang="python">
import numpy as np
import matplotlib.pyplot as plt

class LIFNeuronWithSTDP:
    """
    Leaky Integrate-and-Fire neuron with STDP synapses.
    """

    def __init__(self, tau_m=20.0, v_rest=-70.0, v_thresh=-55.0,
                 v_reset=-75.0, tau_ref=2.0):
        self.tau_m = tau_m
        self.v_rest = v_rest
        self.v_thresh = v_thresh
        self.v_reset = v_reset
        self.tau_ref = tau_ref

        self.v = v_rest
        self.refractory = 0.0

    def step(self, I_syn, dt):
        """Advance neuron by one timestep."""
        spike = False

        if self.refractory &gt; 0:
            self.refractory -= dt
            self.v = self.v_reset
        else:
            dv = (-(self.v - self.v_rest) + I_syn) / self.tau_m
            self.v += dv * dt

            if self.v &gt;= self.v_thresh:
                spike = True
                self.v = self.v_reset
                self.refractory = self.tau_ref

        return spike


class STDPRecurrentNetwork:
    """
    Network of LIF neurons with all-to-all STDP connectivity.
    """

    def __init__(self, n_neurons, params=None):
        self.n = n_neurons

        # Default parameters
        p = params or {}
        self.A_plus = p.get('A_plus', 0.005)
        self.A_minus = p.get('A_minus', 0.00525)
        self.tau_plus = p.get('tau_plus', 20.0)
        self.tau_minus = p.get('tau_minus', 20.0)
        self.w_max = p.get('w_max', 5.0)

        # Initialize neurons
        self.neurons = [LIFNeuronWithSTDP() for _ in range(n_neurons)]

        # Weight matrix (j-&gt;i in W[i,j])
        self.W = np.random.uniform(0.1, 0.3, (n_neurons, n_neurons))
        np.fill_diagonal(self.W, 0)

        # STDP traces
        self.pre_traces = np.zeros(n_neurons)
        self.post_traces = np.zeros(n_neurons)

    def simulate(self, T, dt, external_input=None):
        """
        Simulate network for T milliseconds.

        Parameters:
        -----------
        T : float
            Total simulation time (ms)
        dt : float
            Time step (ms)
        external_input : function(t) -&gt; array
            External current to each neuron at time t

        Returns:
        --------
        spike_times : list of lists
            Spike times for each neuron
        weight_history : list
            Weight matrices at regular intervals
        """
        n_steps = int(T / dt)
        spike_times = [[] for _ in range(self.n)]
        weight_history = []

        for step in range(n_steps):
            t = step * dt

            # Decay traces
            self.pre_traces *= np.exp(-dt / self.tau_plus)
            self.post_traces *= np.exp(-dt / self.tau_minus)

            # Get external input
            I_ext = external_input(t) if external_input else np.zeros(self.n)

            # Compute synaptic input
            I_syn = I_ext.copy()
            for i in range(self.n):
                for j in range(self.n):
                    if i != j:
                        I_syn[i] += self.W[i, j] * self.post_traces[j]

            # Update neurons and collect spikes
            spikes = []
            for i, neuron in enumerate(self.neurons):
                spike = neuron.step(I_syn[i], dt)
                if spike:
                    spikes.append(i)
                    spike_times[i].append(t)

            # Apply STDP for each spike
            for i in spikes:
                # This neuron spiked: update incoming and outgoing weights

                # LTP: strengthen synapses from recently active presynaptic neurons
                for j in range(self.n):
                    if j != i:
                        self.W[i, j] += self.A_plus * self.pre_traces[j]

                # LTD: weaken synapses to recently active postsynaptic neurons
                for j in range(self.n):
                    if j != i:
                        self.W[j, i] -= self.A_minus * self.post_traces[j]

                # Update traces
                self.pre_traces[i] = 1.0
                self.post_traces[i] = 1.0

            # Clip weights
            self.W = np.clip(self.W, 0, self.w_max)
            np.fill_diagonal(self.W, 0)

            # Record weights periodically
            if step % int(100 / dt) == 0:
                weight_history.append(self.W.copy())

        return spike_times, weight_history


# Example: Train on sequential activation
def sequential_input(sequence, timing, strength=30.0, duration=5.0):
    """Generate external input that activates neurons in sequence."""
    def input_func(t):
        I = np.zeros(len(sequence) + 5)  # Network larger than sequence
        for i, (neuron_idx, spike_time) in enumerate(zip(sequence, timing)):
            if spike_time &lt;= t &lt; spike_time + duration:
                I[neuron_idx] = strength
        return I
    return input_func

# Create and train network
network = STDPRecurrentNetwork(n_neurons=8)
sequence = [0, 2, 5, 7]  # Neurons to activate in order
timing = [100, 130, 160, 190]  # Activation times (ms)

input_func = sequential_input(sequence, timing)
spikes, weights = network.simulate(T=500, dt=0.1, external_input=input_func)

print("Final weights along sequence direction:")
for i in range(len(sequence) - 1):
    pre, post = sequence[i], sequence[i+1]
    print(f"  W[{post},{pre}] (from {pre} to {post}) = {network.W[post, pre]:.4f}")
</Code>

  <SingleSelect id="q7">
    <Prompt>In the STDP network simulation, why do we update both pre_traces and post_traces when a neuron spikes?</Prompt>
    <Options>
      <Option correct="true">Because each spike can act as both a presynaptic event (for outgoing synapses) and a postsynaptic event (for incoming synapses)</Option>
      <Option>Because STDP requires symmetric trace updates for mathematical stability</Option>
      <Option>Because pre_traces and post_traces have different time constants</Option>
      <Option>To prevent numerical overflow in the simulation</Option>
    </Options>
  </SingleSelect>

  <H2>Weight Competition and Normalization</H2>

  <Body>STDP naturally implements synaptic competition: synapses that successfully drive postsynaptic firing strengthen at the expense of those that don't. However, this competition can be unstable without additional constraints. Several normalization schemes have been proposed:</Body>

  <Code lang="python">
import numpy as np

class NormalizedSTDP:
    """
    STDP with various normalization schemes for stability.
    """

    @staticmethod
    def subtractive_normalization(W, target_sum, axis=0):
        """
        Normalize weights so each neuron's total input weight equals target.
        Subtracts excess uniformly from all synapses.
        """
        current_sums = W.sum(axis=axis, keepdims=True)
        excess = (current_sums - target_sum) / W.shape[axis]
        W_normalized = W - excess
        return np.clip(W_normalized, 0, None)

    @staticmethod
    def multiplicative_normalization(W, target_sum, axis=0):
        """
        Normalize weights by scaling to maintain target sum.
        Preserves relative weight ratios.
        """
        current_sums = W.sum(axis=axis, keepdims=True)
        scale = target_sum / (current_sums + 1e-10)
        return W * scale

    @staticmethod
    def synaptic_scaling(W, target_rate, actual_rates, learning_rate=0.001):
        """
        Homeostatic synaptic scaling based on firing rate.
        Implements slow homeostatic plasticity.
        """
        # Scale weights to bring firing rate toward target
        rate_error = target_rate - actual_rates
        scaling_factors = 1.0 + learning_rate * rate_error
        return W * scaling_factors[:, np.newaxis]

    @staticmethod
    def oja_normalization(W, post_rate, learning_rate=0.01):
        """
        Oja's rule: multiplicative normalization with weight decay.
        Implements competitive learning with automatic normalization.
        dw = α * pre * post - α * post^2 * w
        """
        decay = learning_rate * post_rate**2 * W
        return W - decay


def demonstrate_competition():
    """Show how STDP leads to input selectivity through competition."""
    n_inputs = 10
    n_output = 1

    # Initialize weights uniformly
    W = np.ones(n_inputs) * 0.5

    # Input correlations: first 5 inputs are correlated, last 5 are uncorrelated
    n_trials = 1000
    A_plus, A_minus = 0.01, 0.012

    for trial in range(n_trials):
        # Generate correlated input pattern
        if np.random.rand() &lt; 0.5:
            # Correlated group fires together
            active_inputs = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])
        else:
            # Random independent activity
            active_inputs = (np.random.rand(n_inputs) &lt; 0.3).astype(float)

        # Output fires based on weighted input
        output_prob = np.clip(np.dot(W, active_inputs) / 5, 0, 1)
        output_spike = np.random.rand() &lt; output_prob

        if output_spike:
            # Apply STDP
            # LTP for active inputs
            W += A_plus * active_inputs
            # LTD for inactive inputs (simplified)
            W -= A_minus * 0.1 * (1 - active_inputs)

        # Apply normalization
        W = np.clip(W, 0, 1)
        W = W * (5.0 / W.sum())  # Maintain constant total weight

    return W

final_weights = demonstrate_competition()
print("Final weights after competition:")
print(f"  Correlated group (0-4): {final_weights[:5].mean():.3f} ± {final_weights[:5].std():.3f}")
print(f"  Uncorrelated group (5-9): {final_weights[5:].mean():.3f} ± {final_weights[5:].std():.3f}")
</Code>

  <Body>The competition demonstration shows how STDP, combined with weight normalization, leads to input selectivity: synapses from inputs that are consistently correlated with postsynaptic firing strengthen, while uncorrelated inputs weaken. This is fundamental to receptive field development and feature selectivity.</Body>

  <Subjective id="q8">
    <Prompt>Explain why STDP alone (without weight normalization or bounds) leads to unstable weight dynamics, and describe at least two biologically plausible mechanisms that could stabilize learning. Include in your answer how these mechanisms relate to experimental observations of homeostatic plasticity.</Prompt>
    <Rubric>
      <Criterion points="4" required="true">
        <Requirement>Correctly explains the instability mechanism: strong synapses drive postsynaptic firing, which leads to more LTP for those synapses, creating positive feedback/runaway potentiation</Requirement>
        <Indicators>positive feedback, runaway, explosion, instability, drives firing, stronger get stronger</Indicators>
      </Criterion>
      <Criterion points="3" required="true">
        <Requirement>Describes at least two stabilization mechanisms (e.g., multiplicative STDP, synaptic scaling, weight normalization, metaplasticity, BCM rule)</Requirement>
        <Indicators>multiplicative, scaling, normalization, metaplasticity, BCM, homeostatic, weight-dependent</Indicators>
      </Criterion>
      <Criterion points="3">
        <Requirement>Connects to experimental evidence (e.g., Turrigiano's synaptic scaling experiments, BCM sliding threshold, heterosynaptic depression)</Requirement>
        <Indicators>Turrigiano, experimental, observed, measured, biological, heterosynaptic, sliding threshold</Indicators>
      </Criterion>
      <Criterion points="2">
        <Requirement>Discusses timescale separation between STDP (fast) and homeostatic mechanisms (slow)</Requirement>
        <Indicators>timescale, slow, fast, hours, days, minutes, milliseconds</Indicators>
      </Criterion>
    </Rubric>
    <Constraints minWords="100" maxWords="400" />
  </Subjective>

  <H2>Common Misconceptions</H2>

  <Body>Several misconceptions about STDP deserve clarification:</Body>

  <Body>1. "STDP always leads to stable learning." In fact, additive STDP without additional constraints produces unstable dynamics and bimodal weight distributions. Stability requires weight-dependent rules, normalization, or homeostatic mechanisms.</Body>

  <Body>2. "STDP is just rate-based Hebbian learning with temporal information." While related, STDP is fundamentally different: it can distinguish causal from anti-causal relationships and operates on spike timing rather than firing rates. Networks can have identical rates but very different STDP outcomes depending on timing correlations.</Body>

  <Body>3. "The temporal asymmetry in STDP always reflects causality." While STDP does detect temporal order, this isn't always causal. Correlated activity without true causation can still drive STDP. Additionally, some synapses show reversed or symmetric STDP windows.</Body>

  <Body>4. "STDP time constants are universal." Different brain regions, cell types, and developmental stages show diverse STDP windows. Some systems show anti-Hebbian STDP (reversed sign), symmetric windows, or timing-independent plasticity.</Body>

  <SingleSelect id="q9">
    <Prompt>Which statement about STDP is FALSE?</Prompt>
    <Options>
      <Option correct="true">STDP time constants and amplitudes are identical across all brain regions and cell types</Option>
      <Option>STDP can produce unstable weight dynamics without additional constraints</Option>
      <Option>STDP can distinguish causal from anti-causal temporal relationships</Option>
      <Option>Some synapses exhibit anti-Hebbian or symmetric STDP windows</Option>
    </Options>
  </SingleSelect>

  <H2>Summary</H2>

  <Body>Spike-timing-dependent plasticity provides a powerful, biologically grounded learning rule that captures the temporal precision of neural coding. Key takeaways:</Body>

  <Body>• STDP modifies synaptic weights based on millisecond-precise spike timing, implementing a form of causality detection</Body>
  <Body>• The asymmetric learning window (LTP for pre→post, LTD for post→pre) emerges from molecular mechanisms involving NMDA receptors and calcium dynamics</Body>
  <Body>• Additive vs. multiplicative implementations have different stability and competition properties</Body>
  <Body>• STDP enables sequence learning, temporal pattern completion, and development of receptive fields</Body>
  <Body>• Connections to reinforcement learning (temporal difference) provide theoretical grounding</Body>
  <Body>• Stability requires additional mechanisms: weight bounds, normalization, or homeostatic plasticity</Body>

  <Body>In subsequent lessons, we will explore how STDP interacts with reward signals (reward-modulated STDP), its role in oscillatory networks, and applications to neuromorphic computing systems.</Body>

</Lesson>
